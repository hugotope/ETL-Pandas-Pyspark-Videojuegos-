{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1900044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02 - Procesamiento y ETL con PySpark\n",
    "\n",
    "# Este notebook replica el flujo de análisis y ETL usando PySpark y carga los resultados en `warehouse/warehouse_pyspark.db`. Ejecuta este notebook desde la raíz del proyecto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf59665c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV: ../data/videogames.csv\n",
      "SQLite DB (PySpark): ../warehouse/warehouse_pyspark.db\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from pyspark.sql import SparkSession, functions as F, Window\n",
    "\n",
    "# Rutas relativas desde notebooks/ hacia data/ y warehouse/\n",
    "DATA_PATH = \"../data/videogames.csv\"\n",
    "DB_PATH = \"../warehouse/warehouse_pyspark.db\"\n",
    "DB_URL = f\"sqlite:///{DB_PATH}\"\n",
    "\n",
    "spark = SparkSession.builder.appName(\"videogames_pyspark_etl\").getOrCreate()\n",
    "\n",
    "print(f\"CSV: {DATA_PATH}\")\n",
    "print(f\"SQLite DB (PySpark): {DB_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62178f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dataset cargado =====\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- cost: string (nullable = true)\n",
      " |-- platform: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- pegi: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- developer: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      " |-- engine: string (nullable = true)\n",
      " |-- award: string (nullable = true)\n",
      " |-- dlc_support: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- metascore: string (nullable = true)\n",
      " |-- user_score: string (nullable = true)\n",
      " |-- reviews: string (nullable = true)\n",
      " |-- rating_source: string (nullable = true)\n",
      " |-- copies_sold_millions: string (nullable = true)\n",
      " |-- revenue_millions_usd: string (nullable = true)\n",
      "\n",
      "Dimensiones del dataset: 10000 filas x 21 columnas\n",
      "\n",
      "Primeras 5 filas:\n",
      "+-------------------+-------+-----+--------+-----------------+----+----+---------+------------+-------+-------------+-------------+-----------+-----------+--------+---------+----------+-----------------+-------------+--------------------+--------------------+\n",
      "|               name|  genre| cost|platform|       popularity|pegi|year|developer|   publisher| region|         mode|       engine|      award|dlc_support|language|metascore|user_score|          reviews|rating_source|copies_sold_millions|revenue_millions_usd|\n",
      "+-------------------+-------+-----+--------+-----------------+----+----+---------+------------+-------+-------------+-------------+-----------+-----------+--------+---------+----------+-----------------+-------------+--------------------+--------------------+\n",
      "|Super Mario Odyssey| Action|74.45|  Mobile|               56|  7+|2011|   Capcom| Square Enix|      ?|  Multiplayer|    CryEngine|Indie Award|    Unknown|      JP|        ?|         ?|9.388708962265735|  Metacritic |               41.93|                   ?|\n",
      "|         God of War|   RPG |    0|  Mobile|                ?|  7+|2023| Rockstar|    Nintendo|Global |       Online|        Unity|          ?|          Y|      DE|     98.1|       8.4|                ?|         IGN |                1.5M|                 N/A|\n",
      "|    Persona 5 Royal|Shooter| Free|      PS|               64|  12|2020| nintendo| Square Enix|     NA|Single-player|Custom Engine|       GotY|          Y|      DE|     31.7|       2.6|                ?|          IGN|               25.08|               889.0|\n",
      "|           NBA 2K24| Puzzle|  N/A|  Mobile|972.7113240416031|  RP|2017|     Sony| Square Enix|Global |Single-player|Custom Engine|       NONE|          ?|      ES|   80/100|       N/A|                ?|   OpenCritic|                 N/A|               $500M|\n",
      "|          Overwatch|      ?| 33.4|      PC|612.6268621737502| 18+|2015| Nintendo|Bandai Namco|  NA/EU|  Multiplayer|       Custom|Indie Award|    Unknown|      IT|     36.0|       2.3|              N/A|   Metacritic|                 N/A|                 $1B|\n",
      "+-------------------+-------+-----+--------+-----------------+----+----+---------+------------+-------+-------------+-------------+-----------+-----------+--------+---------+----------+-----------------+-------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Carga del dataset con Spark\n",
    "\n",
    "raw_df = (\n",
    "    spark.read\n",
    "    .option(\"header\", True)  # Indica que el archivo CSV tiene una fila de encabezados\n",
    "    .option(\"inferSchema\", True)  # Le dice a Spark que detecte automáticamente el tipo de datos\n",
    "    .csv(DATA_PATH)\n",
    ")\n",
    "\n",
    "print(\"===== Dataset cargado =====\")\n",
    "raw_df.printSchema()\n",
    "print(f\"Dimensiones del dataset: {raw_df.count()} filas x {len(raw_df.columns)} columnas\")\n",
    "print(\"\\nPrimeras 5 filas:\")\n",
    "raw_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47d90383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 1. Eliminación de duplicados =====\n",
      "Filas antes: 10000, después: 10000\n",
      "\n",
      "Columnas numéricas detectadas: []\n",
      "Columnas categóricas detectadas: 21 columnas\n",
      "\n",
      "===== 2. Tratamiento de valores faltantes en columnas categóricas =====\n",
      "Valores faltantes y problemáticos reemplazados con 'Unknown'\n",
      "\n",
      "===== Dataset después de limpieza inicial =====\n",
      "+--------------------+----------+-------+--------+------------------+-------+----+----------+-----------+------+-----------+-------------+---------+-----------+--------+---------+----------+-----------------+-------------+--------------------+--------------------+\n",
      "|                name|     genre|   cost|platform|        popularity|   pegi|year| developer|  publisher|region|       mode|       engine|    award|dlc_support|language|metascore|user_score|          reviews|rating_source|copies_sold_millions|revenue_millions_usd|\n",
      "+--------------------+----------+-------+--------+------------------+-------+----+----------+-----------+------+-----------+-------------+---------+-----------+--------+---------+----------+-----------------+-------------+--------------------+--------------------+\n",
      "|       Halo Infinite|Simulation|    $60|      PC|           Unknown|     12|2007|        EA|Square Enix|    EU|    Single |Unreal Engine|Nominated|         No|      EN|   80/100|   Unknown|             9513|      Unknown|                1.5M|               282.3|\n",
      "|          The Sims 4|     Indie|  55.44|      PS|           Unknown|      3|2023|   Unknown|Square Enix|    EU|      Co-op|Unreal Engine|Nominated|         No|      FR|   80/100|   Unknown|          Unknown|         IGN |               34.55|               $500M|\n",
      "|        Unknown Game|    Action|    $46|  Mobile|           Unknown|     7+|2017|  Rockstar|       Sony| NA/EU|Multiplayer|      Unknown|Nominated|         No|      DE|  Unknown|      9/10|          Unknown|         IGN |             Unknown|                 $1B|\n",
      "|Call of Duty: Mod...| Adventure|Unknown|    XBOX|           Unknown|unknown|9999|Activision|Square Enix|Global|     Online|      Unknown|     GotY|          Y|      IT|     30.9|   Unknown|63561.48529850485|   Metacritic|                1.5M|             Unknown|\n",
      "|                    |   Unknown| 101.51| Switch |470.25680871913966|    18+|2018|      Sony|  Microsoft|    JP|      Co-op|        Unity|  Unknown|        Yes|      FR|  Unknown|       4.8|72386.67679635916|  Metacritic |               12.79|             Unknown|\n",
      "+--------------------+----------+-------+--------+------------------+-------+----+----------+-----------+------+-----------+-------------+---------+-----------+--------+---------+----------+-----------------+-------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Tratamiento de nulos y duplicados en Spark\n",
    "\n",
    "print(\"===== 1. Eliminación de duplicados =====\")\n",
    "initial_count = raw_df.count()\n",
    "clean_df = raw_df.dropDuplicates()\n",
    "final_count = clean_df.count()\n",
    "print(f\"Filas antes: {initial_count}, después: {final_count}\")\n",
    "\n",
    "# Identificamos columnas numéricas y categóricas\n",
    "# Nota: Como inferSchema=True detecta todo como string, no habrá columnas numéricas aquí\n",
    "# Las convertiremos después en la siguiente celda\n",
    "numeric_cols = [f.name for f in clean_df.schema.fields if str(f.dataType) in (\"IntegerType\", \"LongType\", \"DoubleType\", \"FloatType\")] \n",
    "cat_cols = [f.name for f in clean_df.schema.fields if f.name not in numeric_cols]\n",
    "\n",
    "print(f\"\\nColumnas numéricas detectadas: {numeric_cols}\")\n",
    "print(f\"Columnas categóricas detectadas: {len(cat_cols)} columnas\")\n",
    "\n",
    "# Tratamiento de nulos en columnas numéricas (si las hay)\n",
    "if numeric_cols:\n",
    "    for col in numeric_cols:\n",
    "        mean_val = clean_df.select(F.mean(F.col(col))).first()[0]\n",
    "        if mean_val is not None:\n",
    "            clean_df = clean_df.na.fill({col: float(mean_val)})\n",
    "            print(f\"Columna '{col}' rellenada con media: {mean_val}\")\n",
    "        else:\n",
    "            clean_df = clean_df.na.fill({col: 0.0})\n",
    "            print(f\"Columna '{col}' rellenada con 0.0 (sin valores válidos)\")\n",
    "\n",
    "# Tratamiento de nulos en columnas categóricas\n",
    "# También tratamos valores problemáticos como \"?\", \"N/A\", etc.\n",
    "print(\"\\n===== 2. Tratamiento de valores faltantes en columnas categóricas =====\")\n",
    "for col in cat_cols:\n",
    "    # Reemplazar valores problemáticos comunes con \"Unknown\"\n",
    "    clean_df = clean_df.withColumn(\n",
    "        col,\n",
    "        F.when(\n",
    "            (F.col(col).isNull()) | \n",
    "            (F.col(col) == \"?\") | \n",
    "            (F.col(col) == \"N/A\") |\n",
    "            (F.col(col) == \"\"),\n",
    "            \"Unknown\"\n",
    "        ).otherwise(F.col(col))\n",
    "    )\n",
    "\n",
    "print(\"Valores faltantes y problemáticos reemplazados con 'Unknown'\")\n",
    "\n",
    "print(\"\\n===== Dataset después de limpieza inicial =====\")\n",
    "clean_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d9c53d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 2. Limpieza de columnas de ventas/ingresos =====\n",
      "Columna 'copies_sold_millions' limpiada y rellenada con media: 10308561.989154695\n",
      "Columna 'revenue_millions_usd' limpiada y rellenada con media: 507393576.9315999\n",
      "\n",
      "===== 3. Limpieza de columnas categóricas =====\n",
      "Columnas categóricas limpiadas correctamente\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "print(\"\\n===== 2. Limpieza de columnas de ventas/ingresos =====\")\n",
    "\n",
    "numeric_target_cols = [\"copies_sold_millions\", \"revenue_millions_usd\"]\n",
    "\n",
    "for col in numeric_target_cols:\n",
    "    if col in clean_df.columns:\n",
    "\n",
    "        # 1️ Normalizamos el texto:\n",
    "        # - quitamos espacios\n",
    "        # - quitamos comas y $\n",
    "        # - pasamos a mayúsculas\n",
    "        clean_df = clean_df.withColumn(\n",
    "            col,\n",
    "            F.upper(\n",
    "                F.regexp_replace(\n",
    "                    F.regexp_replace(F.trim(F.col(col)), \",\", \"\"),\n",
    "                    \"\\\\$\", \"\"\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # 2️ Convertimos valores especiales a NULL\n",
    "        clean_df = clean_df.withColumn(\n",
    "            col,\n",
    "            F.when(\n",
    "                (F.col(col).isNull()) |\n",
    "                (F.col(col).isin(\"UNKNOWN\", \"?\")),\n",
    "                None\n",
    "            )\n",
    "            # 3️ Valores terminados en M → millones\n",
    "            .when(\n",
    "                F.col(col).endswith(\"M\"),\n",
    "                F.regexp_replace(F.col(col), \"M\", \"\").cast(DoubleType()) * 1e6\n",
    "            )\n",
    "            # 4️ Valores terminados en B → billones\n",
    "            .when(\n",
    "                F.col(col).endswith(\"B\"),\n",
    "                F.regexp_replace(F.col(col), \"B\", \"\").cast(DoubleType()) * 1e9\n",
    "            )\n",
    "            # 5️ Intento directo de conversión a número\n",
    "            .otherwise(F.col(col).cast(DoubleType()))\n",
    "        )\n",
    "\n",
    "        # 6️ Calculamos la media de la columna\n",
    "        mean_val = clean_df.select(F.mean(col)).first()[0]\n",
    "\n",
    "        # 7️ Rellenamos los NULL con la media\n",
    "        if mean_val is not None:\n",
    "            clean_df = clean_df.na.fill({col: mean_val})\n",
    "            print(f\"Columna '{col}' limpiada y rellenada con media: {mean_val}\")\n",
    "        else:\n",
    "            clean_df = clean_df.na.fill({col: 0.0})\n",
    "            print(f\"Columna '{col}' sin valores válidos → rellenada con 0.0\")\n",
    "\n",
    "print(\"\\n===== 3. Limpieza de columnas categóricas =====\")\n",
    "\n",
    "# Columnas categóricas = todas menos las numéricas tratadas antes\n",
    "categorical_cols = [\n",
    "    c for c in clean_df.columns\n",
    "    if c not in [\"copies_sold_millions\", \"revenue_millions_usd\"]\n",
    "]\n",
    "\n",
    "for col in categorical_cols:\n",
    "\n",
    "    # 1️ Limpiamos espacios y normalizamos texto\n",
    "    clean_df = clean_df.withColumn(\n",
    "        col,\n",
    "        F.trim(F.col(col))\n",
    "    )\n",
    "\n",
    "    # 2️ Reemplazamos valores problemáticos por NULL\n",
    "    clean_df = clean_df.withColumn(\n",
    "        col,\n",
    "        F.when(\n",
    "            (F.col(col).isNull()) |\n",
    "            (F.col(col) == \"\") |\n",
    "            (F.upper(F.col(col)).isin(\"?\", \"N/A\", \"UNKNOWN\")),\n",
    "            None\n",
    "        ).otherwise(F.col(col))\n",
    "    )\n",
    "\n",
    "    # 3️ Rellenamos los NULL con 'Unknown'\n",
    "    clean_df = clean_df.na.fill({col: \"Unknown\"})\n",
    "\n",
    "print(\"Columnas categóricas limpiadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42bc7a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = false)\n",
      " |-- genre: string (nullable = false)\n",
      " |-- cost: string (nullable = false)\n",
      " |-- platform: string (nullable = false)\n",
      " |-- popularity: string (nullable = false)\n",
      " |-- pegi: string (nullable = false)\n",
      " |-- year: string (nullable = false)\n",
      " |-- developer: string (nullable = false)\n",
      " |-- publisher: string (nullable = false)\n",
      " |-- region: string (nullable = false)\n",
      " |-- mode: string (nullable = false)\n",
      " |-- engine: string (nullable = false)\n",
      " |-- award: string (nullable = false)\n",
      " |-- dlc_support: string (nullable = false)\n",
      " |-- language: string (nullable = false)\n",
      " |-- metascore: string (nullable = false)\n",
      " |-- user_score: string (nullable = false)\n",
      " |-- reviews: string (nullable = false)\n",
      " |-- rating_source: string (nullable = false)\n",
      " |-- copies_sold_millions: double (nullable = false)\n",
      " |-- revenue_millions_usd: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalización de nombres de columnas\n",
    "\n",
    "normalized_cols = [\n",
    "    c.strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\") for c in clean_df.columns\n",
    "]\n",
    "clean_df = clean_df.toDF(*normalized_cols)\n",
    "\n",
    "clean_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe122d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas disponibles después de normalización:\n",
      "['name', 'genre', 'cost', 'platform', 'popularity', 'pegi', 'year', 'developer', 'publisher', 'region', 'mode', 'engine', 'award', 'dlc_support', 'language', 'metascore', 'user_score', 'reviews', 'rating_source', 'copies_sold_millions', 'revenue_millions_usd']\n",
      "\n",
      "===== Creación de dimensiones =====\n",
      "Dimensión 'dim_game' creada: 408 filas\n",
      "Dimensión 'dim_platform' creada: 9 filas\n",
      "Dimensión 'dim_developer' creada: 13 filas\n",
      "Dimensión 'dim_publisher' creada: 12 filas\n",
      "Dimensión 'dim_year' creada: 42 filas\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "cols = clean_df.columns\n",
    "required_cols = [\"name\", \"genre\", \"platform\", \"developer\", \"publisher\", \"year\"]\n",
    "for c in required_cols:\n",
    "    if c not in cols:\n",
    "        raise ValueError(f\"Columna requerida no encontrada en el CSV: {c}\")\n",
    "\n",
    "print(\"Columnas disponibles después de normalización:\")\n",
    "print(cols)\n",
    "\n",
    "print(\"\\n===== Creación de dimensiones =====\")\n",
    "\n",
    "# Dimensión: dim_game\n",
    "dim_game_pd = (\n",
    "    clean_df.select(\"name\", \"genre\")\n",
    "    .distinct()\n",
    "    .orderBy(\"name\", \"genre\")\n",
    "    .toPandas()\n",
    ")\n",
    "dim_game_pd[\"id_game\"] = range(1, len(dim_game_pd) + 1)\n",
    "dim_game = spark.createDataFrame(dim_game_pd)\n",
    "print(f\"Dimensión 'dim_game' creada: {len(dim_game_pd)} filas\")\n",
    "\n",
    "# Dimensión: dim_platform\n",
    "dim_platform_pd = clean_df.select(\"platform\").distinct().orderBy(\"platform\").toPandas()\n",
    "dim_platform_pd[\"id_platform\"] = range(1, len(dim_platform_pd) + 1)\n",
    "dim_platform = spark.createDataFrame(dim_platform_pd)\n",
    "print(f\"Dimensión 'dim_platform' creada: {len(dim_platform_pd)} filas\")\n",
    "\n",
    "# Dimensión: dim_developer\n",
    "dim_developer_pd = clean_df.select(\"developer\").distinct().orderBy(\"developer\").toPandas()\n",
    "dim_developer_pd[\"id_developer\"] = range(1, len(dim_developer_pd) + 1)\n",
    "dim_developer = spark.createDataFrame(dim_developer_pd)\n",
    "print(f\"Dimensión 'dim_developer' creada: {len(dim_developer_pd)} filas\")\n",
    "\n",
    "# Dimensión: dim_publisher\n",
    "dim_publisher_pd = clean_df.select(\"publisher\").distinct().orderBy(\"publisher\").toPandas()\n",
    "dim_publisher_pd[\"id_publisher\"] = range(1, len(dim_publisher_pd) + 1)\n",
    "dim_publisher = spark.createDataFrame(dim_publisher_pd)\n",
    "print(f\"Dimensión 'dim_publisher' creada: {len(dim_publisher_pd)} filas\")\n",
    "\n",
    "# Dimensión: dim_year\n",
    "dim_year_pd = clean_df.select(\"year\").distinct().orderBy(\"year\").toPandas()\n",
    "dim_year_pd[\"id_year\"] = range(1, len(dim_year_pd) + 1)\n",
    "dim_year = spark.createDataFrame(dim_year_pd)\n",
    "print(f\"Dimensión 'dim_year' creada: {len(dim_year_pd)} filas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2af484a4-8e0c-4ac8-97de-a8a24f0a5208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tabla de hechos 'fact_sales' creada: 10000 filas\n",
      "+-------+-----------+------------+------------+-------+--------------------+--------------------+\n",
      "|id_game|id_platform|id_developer|id_publisher|id_year|copies_sold_millions|revenue_millions_usd|\n",
      "+-------+-----------+------------+------------+-------+--------------------+--------------------+\n",
      "|    200|          3|           5|          10|     23|           1500000.0|               282.3|\n",
      "|    339|          4|          12|          10|     39|               34.55|               5.0E8|\n",
      "|    373|          1|           8|           9|     33|1.0308561989154695E7|               1.0E9|\n",
      "|     38|          7|           1|          10|     41|           1500000.0| 5.073935769315999E8|\n",
      "|    371|          6|           9|           6|     34|               12.79| 5.073935769315999E8|\n",
      "+-------+-----------+------------+------------+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------\n",
    "# Construcción de la tabla de hechos (fact_sales)\n",
    "# -------------------------------------------------------\n",
    "fact = (\n",
    "    clean_df\n",
    "    .join(dim_game, on=[\"name\", \"genre\"], how=\"left\")\n",
    "    .join(dim_platform, on=[\"platform\"], how=\"left\")\n",
    "    .join(dim_developer, on=[\"developer\"], how=\"left\")\n",
    "    .join(dim_publisher, on=[\"publisher\"], how=\"left\")\n",
    "    .join(dim_year, on=[\"year\"], how=\"left\")\n",
    ")\n",
    "\n",
    "# Columnas métricas\n",
    "value_cols = [c for c in [\"copies_sold_millions\", \"revenue_millions_usd\"] if c in fact.columns]\n",
    "if not value_cols:\n",
    "    raise ValueError(\"No se encontraron columnas métricas para construir la tabla de hechos.\")\n",
    "\n",
    "# Selección final de la tabla de hechos\n",
    "fact_sales = fact.select(\n",
    "    \"id_game\", \"id_platform\", \"id_developer\", \"id_publisher\", \"id_year\", *value_cols\n",
    ")\n",
    "\n",
    "print(f\"\\nTabla de hechos 'fact_sales' creada: {fact_sales.count()} filas\")\n",
    "fact_sales.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2bee5d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Carga de tablas en SQLite =====\n",
      "Directorio warehouse: /app/warehouse\n",
      "Base de datos: /app/warehouse/warehouse_pyspark.db\n",
      "\n",
      "Cargando tablas en SQLite...\n",
      " - dim_game cargada\n",
      " - dim_platform cargada\n",
      " - dim_developer cargada\n",
      " - dim_publisher cargada\n",
      " - dim_year cargada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - fact_sales cargada\n",
      "\n",
      "✅ Todas las tablas fueron cargadas correctamente en SQLite: /app/warehouse/warehouse_pyspark.db\n"
     ]
    }
   ],
   "source": [
    "# Carga a SQLite: usamos los DataFrames de Pandas directamente (ya creados arriba)\n",
    "# y convertimos fact_sales de Spark a Pandas\n",
    "\n",
    "print(\"===== Carga de tablas en SQLite =====\")\n",
    "\n",
    "# Obtener la ruta absoluta del directorio warehouse\n",
    "# Si estamos en notebooks/, subimos un nivel y vamos a warehouse/\n",
    "current_dir = os.getcwd()\n",
    "if \"notebooks\" in current_dir:\n",
    "    # Estamos en notebooks/, subimos un nivel\n",
    "    project_root = os.path.dirname(current_dir)\n",
    "else:\n",
    "    # Estamos en la raíz del proyecto\n",
    "    project_root = current_dir\n",
    "\n",
    "warehouse_dir = os.path.join(project_root, \"warehouse\")\n",
    "os.makedirs(warehouse_dir, exist_ok=True)\n",
    "\n",
    "# Usar ruta absoluta para la base de datos\n",
    "db_path_abs = os.path.join(warehouse_dir, \"warehouse_pyspark.db\")\n",
    "db_url_abs = f\"sqlite:///{db_path_abs}\"\n",
    "\n",
    "print(f\"Directorio warehouse: {warehouse_dir}\")\n",
    "print(f\"Base de datos: {db_path_abs}\")\n",
    "\n",
    "engine = sqlalchemy.create_engine(db_url_abs)\n",
    "\n",
    "print(\"\\nCargando tablas en SQLite...\")\n",
    "with engine.begin() as conn:\n",
    "    # Usar directamente los DataFrames de Pandas (ya creados sin ventanas)\n",
    "    dim_game_pd.to_sql(\"dim_game\", conn, if_exists=\"replace\", index=False)\n",
    "    print(\" - dim_game cargada\")\n",
    "    dim_platform_pd.to_sql(\"dim_platform\", conn, if_exists=\"replace\", index=False)\n",
    "    print(\" - dim_platform cargada\")\n",
    "    dim_developer_pd.to_sql(\"dim_developer\", conn, if_exists=\"replace\", index=False)\n",
    "    print(\" - dim_developer cargada\")\n",
    "    dim_publisher_pd.to_sql(\"dim_publisher\", conn, if_exists=\"replace\", index=False)\n",
    "    print(\" - dim_publisher cargada\")\n",
    "    dim_year_pd.to_sql(\"dim_year\", conn, if_exists=\"replace\", index=False)\n",
    "    print(\" - dim_year cargada\")\n",
    "    # fact_sales necesita conversión de Spark a Pandas (no tiene ventanas, no generará warnings)\n",
    "    fact_sales.toPandas().to_sql(\"fact_sales\", conn, if_exists=\"replace\", index=False)\n",
    "    print(\" - fact_sales cargada\")\n",
    "\n",
    "print(f\"\\n✅ Todas las tablas fueron cargadas correctamente en SQLite: {db_path_abs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1816ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Consulta: Top 10 géneros por ventas =====\n",
      "Consulta SQL ejecutada:\n",
      " \n",
      "SELECT \n",
      "    g.genre, \n",
      "    SUM(f.copies_sold_millions) AS total_copies_sold,\n",
      "    SUM(f.revenue_millions_usd) AS total_revenue\n",
      "FROM fact_sales f\n",
      "JOIN dim_game g ON f.id_game = g.id_game\n",
      "GROUP BY g.genre\n",
      "ORDER BY total_copies_sold DESC\n",
      "LIMIT 10;\n",
      "\n",
      "\n",
      "===== Resultado: Top 10 géneros por ventas =====\n",
      "        genre  total_copies_sold  total_revenue\n",
      "0     Unknown       1.562467e+10   7.476407e+11\n",
      "1         RPG       1.517758e+10   7.241629e+11\n",
      "2   Adventure       7.897487e+09   3.712996e+11\n",
      "3      Racing       7.627009e+09   3.621147e+11\n",
      "4      Puzzle       7.557338e+09   3.651739e+11\n",
      "5      Action       7.435295e+09   3.571295e+11\n",
      "6       Indie       7.223987e+09   3.715186e+11\n",
      "7      Sports       7.216199e+09   3.760925e+11\n",
      "8      action       7.136507e+09   3.556443e+11\n",
      "9  Simulation       6.870018e+09   3.470851e+11\n",
      "\n",
      "===== Resumen del Data Warehouse =====\n",
      "Base de datos creada en: /app/warehouse/warehouse_pyspark.db\n",
      "\n",
      "Tablas creadas:\n",
      "  - dim_game (dimensiones de juegos)\n",
      "  - dim_platform (dimensiones de plataformas)\n",
      "  - dim_developer (dimensiones de desarrolladores)\n",
      "  - dim_publisher (dimensiones de publishers)\n",
      "  - dim_year (dimensiones de años)\n",
      "  - fact_sales (tabla de hechos con ventas)\n",
      "\n",
      "✅ Proceso ETL con PySpark completado exitosamente\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de consulta sobre el Data Warehouse generado por PySpark\n",
    "\n",
    "print(\"===== Consulta: Top 10 géneros por ventas =====\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    g.genre, \n",
    "    SUM(f.copies_sold_millions) AS total_copies_sold,\n",
    "    SUM(f.revenue_millions_usd) AS total_revenue\n",
    "FROM fact_sales f\n",
    "JOIN dim_game g ON f.id_game = g.id_game\n",
    "GROUP BY g.genre\n",
    "ORDER BY total_copies_sold DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "print(\"Consulta SQL ejecutada:\\n\", query)\n",
    "\n",
    "# Usar la misma conexión que creamos arriba\n",
    "with engine.connect() as conn:\n",
    "    top_genres_spark = pd.read_sql(query, conn)\n",
    "\n",
    "print(\"\\n===== Resultado: Top 10 géneros por ventas =====\")\n",
    "print(top_genres_spark)\n",
    "\n",
    "print(\"\\n===== Resumen del Data Warehouse =====\")\n",
    "print(f\"Base de datos creada en: {db_path_abs}\")\n",
    "print(\"\\nTablas creadas:\")\n",
    "print(\"  - dim_game (dimensiones de juegos)\")\n",
    "print(\"  - dim_platform (dimensiones de plataformas)\")\n",
    "print(\"  - dim_developer (dimensiones de desarrolladores)\")\n",
    "print(\"  - dim_publisher (dimensiones de publishers)\")\n",
    "print(\"  - dim_year (dimensiones de años)\")\n",
    "print(\"  - fact_sales (tabla de hechos con ventas)\")\n",
    "print(\"\\n✅ Proceso ETL con PySpark completado exitosamente\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c77911-32d5-46ff-b3b7-c33b8246640d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
